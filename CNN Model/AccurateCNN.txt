% Define paths to your image folders (Week 2 to Week 5, etc.)
week2Folder = 'C:\Users\chris\Downloads\Optimized-Controlled-Environment-for-Plant-Growth-Using-CNN-and-Self-Adaptive-Algorithm-main\Optimized-Controlled-Environment-for-Plant-Growth-Using-CNN-and-Self-Adaptive-Algorithm-main\Datasets\Images\S2\Week 2';
week3Folder = 'C:\Users\chris\Downloads\Optimized-Controlled-Environment-for-Plant-Growth-Using-CNN-and-Self-Adaptive-Algorithm-main\Optimized-Controlled-Environment-for-Plant-Growth-Using-CNN-and-Self-Adaptive-Algorithm-main\Datasets\Images\S3\Week 3';
week4Folder = 'C:\Users\chris\Downloads\Optimized-Controlled-Environment-for-Plant-Growth-Using-CNN-and-Self-Adaptive-Algorithm-main\Optimized-Controlled-Environment-for-Plant-Growth-Using-CNN-and-Self-Adaptive-Algorithm-main\Datasets\Images\S4\Week 4';
week5Folder = 'C:\Users\chris\Downloads\Optimized-Controlled-Environment-for-Plant-Growth-Using-CNN-and-Self-Adaptive-Algorithm-main\Optimized-Controlled-Environment-for-Plant-Growth-Using-CNN-and-Self-Adaptive-Algorithm-main\Datasets\Images\S5\Week 5';

% Load images from each week folder (each folder corresponds to a label)
imds2 = imageDatastore(week2Folder, 'LabelSource', 'foldernames');  % Week 2 images
imds3 = imageDatastore(week3Folder, 'LabelSource', 'foldernames');  % Week 3 images
imds4 = imageDatastore(week4Folder, 'LabelSource', 'foldernames');  % Week 4 images
imds5 = imageDatastore(week5Folder, 'LabelSource', 'foldernames');  % Week 5 images

% Combine the image datastores from all weeks
imds = imageDatastore([imds2.Files; imds3.Files; imds4.Files; imds5.Files], 'LabelSource', 'foldernames');  

% Shuffle the data before splitting into batches
imds = shuffle(imds);
totalImages = numel(imds.Files);
fprintf('Total images in dataset: %d\n', totalImages);

% Split the dataset into training and validation sets (80% training, 20% validation)
[imdsTrain, imdsVal] = splitEachLabel(imds, 0.8, 'randomized');
fprintf('Training images: %d\n', numel(imdsTrain.Files));
fprintf('Validation images: %d\n', numel(imdsVal.Files));

% Resize images to the size expected by the model (224x224 for ResNet)
inputSize = [224 224 3]; % Adjust for grayscale if needed
imdsTrain.ReadFcn = @(filename)imresize(imread(filename), inputSize(1:2));
imdsVal.ReadFcn = @(filename)imresize(imread(filename), inputSize(1:2));
    
% Determine the number of training images
numTrainImages = numel(imdsTrain.Files);

% Load the pre-trained network (ResNet-50)
net = resnet50;

% Create a layer graph from the ResNet-50 network
lgraph = layerGraph(net);

% Modify the layers for your task
numClasses = 4;  % Number of classes (Week 2 to Week 5)

% Replace the fully connected layer and the classification layer
newFcLayer = fullyConnectedLayer(numClasses, 'WeightLearnRateFactor', 10, 'BiasLearnRateFactor', 10, 'Name', 'new_fc');
newClassLayer = classificationLayer('Name', 'new_class');

% Remove the last layers and add new ones
lgraph = replaceLayer(lgraph, 'fc1000', newFcLayer); % Replace the fully connected layer
lgraph = replaceLayer(lgraph, 'ClassificationLayer_fc1000', newClassLayer); % Replace the classification layer

% Define the training options
options = trainingOptions('sgdm', ...
    'InitialLearnRate', 0.001, ...
    'MaxEpochs', 15, ...
    'MiniBatchSize', 35, ...
    'Shuffle', 'every-epoch', ...
    'ValidationData', imdsVal, ...
    'ValidationFrequency', floor(numel(imdsTrain.Files) / 35), ...
    'ValidationPatience', 5, ...
    'Verbose', true, ...
    'Plots', 'training-progress', ...
    'OutputFcn', @(info) plotAccuracy(info));

% Train the Model - Using All Training Data
netTransfer = trainNetwork(imdsTrain, lgraph, options);

% Function to plot accuracy
function plotAccuracy(info)
    persistent trainAcc valAcc
    if info.State == "start"
        trainAcc = [];
        valAcc = [];
    end
    
    if info.State == "iteration"
        trainAcc = [trainAcc, info.TrainingLoss];
        valAcc = [valAcc, info.ValidationLoss];
    end
    
    % Plot the accuracy/loss graph after each epoch
    if info.State == "done"
        figure;
        plot(1:length(trainAcc), trainAcc, '-o', 'DisplayName', 'Train Accuracy');
        hold on;
        plot(1:length(valAcc), valAcc, '-x', 'DisplayName', 'Validation Accuracy');
        xlabel('Epoch');
        ylabel('Accuracy');
        legend;
        title('Training and Validation Accuracy');
        grid on;
    end
end

% Evaluate the model on the validation set
YPred = classify(netTransfer, imdsVal);  % Use classify for classification
YValidation = imdsVal.Labels;  % Correct way to get the true labels

% Compute Accuracy
accuracy = mean(YPred == YValidation);
fprintf('Validation Accuracy: %.2f%%\n', accuracy * 100);

% **Visualize Confusion Matrix**
figure;
confusionchart(YValidation, YPred);
title('Confusion Matrix: ');

% Optionally, visualize results (predicted vs actual weeks)
figure;
plot(double(YValidation), double(YPred), 'o');  % Convert labels to numeric for plotting
xlabel('True Label (Week)');
ylabel('Predicted Label (Week)');
title('Prediction vs Actual Week');
